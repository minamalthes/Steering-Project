{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "075a5581",
   "metadata": {},
   "source": [
    "# Notebook 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20588f7a",
   "metadata": {},
   "source": [
    "In this notebook we will showcase the fundamental functions needed to do the analysis. We are here looking at three essential parts:\n",
    "1. [Embeddings](#embeddings)\n",
    "2. [Steering](#steering)\n",
    "3. [Steering Vector](#steering-vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbeb0bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the path to the Functions directory\n",
    "\n",
    "import sys\n",
    "sys.path.append('../Functions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c5dd02",
   "metadata": {},
   "source": [
    "## Functions used in this Notebook:\n",
    "\n",
    "### From \"Embeddings.py\":\n",
    "- [import_data](#import-data) - Import movie data from pickle file\n",
    "- [get_embeddings](#get-embeddings) - Generate embeddings using transformer model\n",
    "- [show_hidden_states](#show-hidden-states) - Display information about model layers\n",
    "- [export_embeddings_to_pkl](#export-embeddings) - Save embeddings and model data to file\n",
    "- [import_embedding_data_from_pkl](#import-embeddings) - Load embeddings and model data from file\n",
    "\n",
    "### From \"Steering_vector.py\": \n",
    "- [import_feature_texts](#import-feature-texts) - Load feature texts for steering vector creation\n",
    "- [get_steering_vector](#get-steering-vector) - Create steering vector from feature texts\n",
    "- [export_steering_vector_to_pkl](#export-steering-vector) - Save steering vector to file\n",
    "- [import_steering_vector_from_pkl](#import-steering-vector) - Load steering vector from file\n",
    "\n",
    "### From \"Steering.py\":\n",
    "- [get_steered_embeddings_vector](#get-steered-embeddings-vector) - Apply steering using semantic vector\n",
    "- [get_steered_embeddings_neuron](#get-steered-embeddings-neuron) - Apply steering using specific neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94b6d7f",
   "metadata": {},
   "source": [
    "## Import Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "188db1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary functions\n",
    "from Embeddings import import_data, get_embeddings, show_hidden_states, export_embeddings_to_pkl, import_embedding_data_from_pkl\n",
    "from Steering_vector import import_feature_texts, get_steering_vector, export_steering_vector_to_pkl, import_steering_vector_from_pkl\n",
    "from Steering import get_steered_embeddings_vector, get_steered_embeddings_neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bd8fa1",
   "metadata": {},
   "source": [
    "***\n",
    "# <a id=\"embeddings\"></a>Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31048525",
   "metadata": {},
   "source": [
    "The following functions are imported from the file `\"Embeddings.py\"`. They are used to create the embeddings, as well as other necessary outputs such as `encoded_input` and `hidden_states`. We also export and import the data for ease of use in other files and notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1f4da57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from Embeddings import import_data, get_embeddings, show_hidden_states, export_embeddings_to_pkl, import_embedding_data_from_pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23fe956",
   "metadata": {},
   "source": [
    "## <a id=\"import-data\"></a>Data Import\n",
    "\n",
    "Essential for the structure of the functions is to have the data in a specific format.\n",
    "To import data, use the `import_data` function. This function imports from a `.pkl` file, in our example containing the IMDb top 1000 movies with their best fit genre. We will use this throughout the showcase.\n",
    "This file needs to have three columns that contain:\n",
    "- A title\n",
    "- An overview of the text (this is the text we will use for embeddings)\n",
    "- A label\n",
    "\n",
    "These columns need to be stored in a `DataFrame` with the names `'title'`, `'overview'`, and `'genre'` respectively. You can have other columns as well but these will not be used. These are stored in `all_texts_data`. Change the function `import_data` in `\"Embeddings.py\"` if needed.\n",
    "\n",
    "If you want to use a different model, you will perhaps need to change the architecture of the files `\"Embeddings.py\"` and `\"Steering.py\"` to fit the model.\n",
    "Here we use the `all-MiniLM-L12-v2` model, which is a good choice for many tasks.\n",
    "\n",
    "## <a id=\"get-embeddings\"></a>Get Embeddings and <a id=\"show-hidden-states\"></a>Show Hidden States\n",
    "\n",
    "Below we demonstrate how to get embeddings and display hidden state information.\n",
    "The `get_embeddings` function  takes in the `model name` and `overview` column returns:\n",
    "- `model:` the loaded Transformer (e.g. `AutoModel`) configured for inference\n",
    "- `tokenizer:` the matching tokenizer used to turn `texts` into tensors\n",
    "- `model_output:` the raw `ModelOutput`(e.g. Hugging Face) with fields like `last_hidden_state`, and - because `output_hidden_states=True`- `hidden_states`\n",
    "- `embeddings:` a `(batch_size, hidden_size)`tensor of sentence embeddings from mean-pooling the token embeddings, optionally L2-normalized when `normalize=true`\n",
    "- `encoded_input:` the tokenzied inputs (dict with `input_ids`, `attention_mask`, and possibly `token_type_ids`) as PyTorch tensors\n",
    "- `hidden_states:` a tuple of length `num_layers + 1`; element `0`is the embedding layer, and elements `1..num_layers`are the per-layer outputs. Each has shape `(batch_size, seq_len, hidden_size)`.\n",
    "\n",
    "`show_hidden_states` simply prints out a description of the hidden states \n",
    "\n",
    "`all_texts_data` will be frequently used, and is the imported dataframe with at least the columns `title`, `genre` and `overview`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb4abb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data imported successfully.\n",
      "Number of texts: 1000\n",
      "                                         Poster_Link  \\\n",
      "0  https://m.media-amazon.com/images/M/MV5BMDFkYT...   \n",
      "1  https://m.media-amazon.com/images/M/MV5BM2MyNj...   \n",
      "2  https://m.media-amazon.com/images/M/MV5BMTMxNT...   \n",
      "3  https://m.media-amazon.com/images/M/MV5BMWMwMG...   \n",
      "4  https://m.media-amazon.com/images/M/MV5BMWU4N2...   \n",
      "\n",
      "                      title Released_Year Certificate  Runtime  IMDB_Rating  \\\n",
      "0  The Shawshank Redemption          1994           A  142 min          9.3   \n",
      "1             The Godfather          1972           A  175 min          9.2   \n",
      "2           The Dark Knight          2008          UA  152 min          9.0   \n",
      "3    The Godfather: Part II          1974           A  202 min          9.0   \n",
      "4              12 Angry Men          1957           U   96 min          9.0   \n",
      "\n",
      "                                            overview  Meta_score  \\\n",
      "0  Two imprisoned men bond over a number of years...        80.0   \n",
      "1  An organized crime dynasty's aging patriarch t...       100.0   \n",
      "2  When the menace known as the Joker wreaks havo...        84.0   \n",
      "3  The early life and career of Vito Corleone in ...        90.0   \n",
      "4  A jury holdout attempts to prevent a miscarria...        96.0   \n",
      "\n",
      "               Director           Star1           Star2          Star3  \\\n",
      "0        Frank Darabont     Tim Robbins  Morgan Freeman     Bob Gunton   \n",
      "1  Francis Ford Coppola   Marlon Brando       Al Pacino     James Caan   \n",
      "2     Christopher Nolan  Christian Bale    Heath Ledger  Aaron Eckhart   \n",
      "3  Francis Ford Coppola       Al Pacino  Robert De Niro  Robert Duvall   \n",
      "4          Sidney Lumet     Henry Fonda     Lee J. Cobb  Martin Balsam   \n",
      "\n",
      "            Star4  No_of_Votes        Gross  genre  \n",
      "0  William Sadler      2343110   28,341,469  Drama  \n",
      "1    Diane Keaton      1620367  134,966,411  Crime  \n",
      "2   Michael Caine      2303232  534,858,444  Crime  \n",
      "3    Diane Keaton      1129952   57,300,000  Drama  \n",
      "4    John Fiedler       689845    4,360,000  Drama  \n",
      "Model and tokenizer set for sentence-transformers/all-MiniLM-L12-v2\n",
      "Model and tokenizer set for sentence-transformers/all-MiniLM-L12-v2\n",
      "Got embeddings for 1000 texts using model: sentence-transformers/all-MiniLM-L12-v2\n",
      "Number of transformer layers: 12\n",
      "Note: Layer 0 is the embedding output (before first encoder layer)\n",
      "\n",
      "Embedding output (hidden_states[0]) shape: torch.Size([1000, 66, 384])\n",
      "Encoder Layer 0  --> output in hidden_states[1], Shape: torch.Size([1000, 66, 384])\n",
      "Encoder Layer 1  --> output in hidden_states[2], Shape: torch.Size([1000, 66, 384])\n",
      "Encoder Layer 2  --> output in hidden_states[3], Shape: torch.Size([1000, 66, 384])\n",
      "Encoder Layer 3  --> output in hidden_states[4], Shape: torch.Size([1000, 66, 384])\n",
      "Encoder Layer 4  --> output in hidden_states[5], Shape: torch.Size([1000, 66, 384])\n",
      "Encoder Layer 5  --> output in hidden_states[6], Shape: torch.Size([1000, 66, 384])\n",
      "Encoder Layer 6  --> output in hidden_states[7], Shape: torch.Size([1000, 66, 384])\n",
      "Encoder Layer 7  --> output in hidden_states[8], Shape: torch.Size([1000, 66, 384])\n",
      "Encoder Layer 8  --> output in hidden_states[9], Shape: torch.Size([1000, 66, 384])\n",
      "Encoder Layer 9  --> output in hidden_states[10], Shape: torch.Size([1000, 66, 384])\n",
      "Encoder Layer 10  --> output in hidden_states[11], Shape: torch.Size([1000, 66, 384])\n",
      "Encoder Layer 11  --> output in hidden_states[12], Shape: torch.Size([1000, 66, 384])\n",
      "Got embeddings for 1000 texts using model: sentence-transformers/all-MiniLM-L12-v2\n",
      "Number of transformer layers: 12\n",
      "Note: Layer 0 is the embedding output (before first encoder layer)\n",
      "\n",
      "Embedding output (hidden_states[0]) shape: torch.Size([1000, 66, 384])\n",
      "Encoder Layer 0  --> output in hidden_states[1], Shape: torch.Size([1000, 66, 384])\n",
      "Encoder Layer 1  --> output in hidden_states[2], Shape: torch.Size([1000, 66, 384])\n",
      "Encoder Layer 2  --> output in hidden_states[3], Shape: torch.Size([1000, 66, 384])\n",
      "Encoder Layer 3  --> output in hidden_states[4], Shape: torch.Size([1000, 66, 384])\n",
      "Encoder Layer 4  --> output in hidden_states[5], Shape: torch.Size([1000, 66, 384])\n",
      "Encoder Layer 5  --> output in hidden_states[6], Shape: torch.Size([1000, 66, 384])\n",
      "Encoder Layer 6  --> output in hidden_states[7], Shape: torch.Size([1000, 66, 384])\n",
      "Encoder Layer 7  --> output in hidden_states[8], Shape: torch.Size([1000, 66, 384])\n",
      "Encoder Layer 8  --> output in hidden_states[9], Shape: torch.Size([1000, 66, 384])\n",
      "Encoder Layer 9  --> output in hidden_states[10], Shape: torch.Size([1000, 66, 384])\n",
      "Encoder Layer 10  --> output in hidden_states[11], Shape: torch.Size([1000, 66, 384])\n",
      "Encoder Layer 11  --> output in hidden_states[12], Shape: torch.Size([1000, 66, 384])\n"
     ]
    }
   ],
   "source": [
    "# Import data for a chosen number of texts from the pkl file\n",
    "all_texts_data = import_data(file_path=\"../imdb_top_1000_with_best_fit_genre.pkl\", number_of_texts=1000)\n",
    "texts = all_texts_data['overview'].tolist()[:1000]  # Use the overview column for text data\n",
    "\n",
    "# Choose a model\n",
    "model_name = \"sentence-transformers/all-MiniLM-L12-v2\"\n",
    "\n",
    "# Get the embeddings and other model outputs\n",
    "model, tokenizer, model_output, embeddings, encoded_input, hidden_states = get_embeddings(model_name, texts)\n",
    "\n",
    "# Show hidden states information\n",
    "show_hidden_states(hidden_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a277bbf8",
   "metadata": {},
   "source": [
    "## <a id=\"export-embeddings\"></a>Export Embeddings\n",
    "\n",
    "All necessary data from `get_embeddings` can now be exported to a pkl file using the function `export_embeddings_to_pkl`, the parameters will be dumped to the pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c17db2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings exported to Test_export_embeddings.pkl\n"
     ]
    }
   ],
   "source": [
    "export_embeddings_to_pkl(\n",
    "    model_name, \n",
    "    model, \n",
    "    tokenizer, \n",
    "    model_output, \n",
    "    embeddings, \n",
    "    encoded_input, \n",
    "    hidden_states, \n",
    "    all_texts_data, \n",
    "    file_path=\"Test_export_embeddings.pkl\" # Choose a filepath to save the embeddings\n",
    "    ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e48b19",
   "metadata": {},
   "source": [
    "## <a id=\"import-embeddings\"></a>Import Embeddings\n",
    "\n",
    "`import_embedding_data_from_pkl` allows you to import all necessary data from the exported pkl file. \n",
    "By default, no data will be imported, but you can set the parameters to `wanted_data=True` to import specific data.\n",
    "Only the specified data will be returned by the function. \n",
    "The parameters must be called in the same order as they are defined in the function, shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1f01827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing 1.36 GB data from file Test_export_embeddings.pkl...\n",
      "Data imported from Test_export_embeddings.pkl\n",
      "Model name: sentence-transformers/all-MiniLM-L12-v2\n",
      "Model loaded successfully.\n",
      "Tokenizer loaded successfully.\n",
      "Model output loaded successfully.\n",
      "Embeddings loaded successfully.\n",
      "Encoded input loaded successfully.\n",
      "Hidden states loaded successfully.\n",
      "All texts data loaded successfully.\n",
      "Data imported from Test_export_embeddings.pkl\n",
      "Model name: sentence-transformers/all-MiniLM-L12-v2\n",
      "Model loaded successfully.\n",
      "Tokenizer loaded successfully.\n",
      "Model output loaded successfully.\n",
      "Embeddings loaded successfully.\n",
      "Encoded input loaded successfully.\n",
      "Hidden states loaded successfully.\n",
      "All texts data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Here we import all data from the exported pkl file\n",
    "import_embedding_data_from_pkl(\"Test_export_embeddings.pkl\", # Filepath to the pkl file\n",
    "                               model_name=True, \n",
    "                               model=True, \n",
    "                               tokenizer=True, \n",
    "                               model_output=True, \n",
    "                               embeddings=True, \n",
    "                               encoded_input=True, \n",
    "                               hidden_states=True, \n",
    "                               all_texts_data=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50795551",
   "metadata": {},
   "source": [
    "Here is another example of how to use the `import_embedding_data_from_pkl` function, only importing some of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc3ae095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing 1.36 GB data from file Test_export_embeddings.pkl...\n",
      "Data imported from Test_export_embeddings.pkl\n",
      "Model loaded successfully.\n",
      "Embeddings loaded successfully.\n",
      "Hidden states loaded successfully.\n",
      "Data imported from Test_export_embeddings.pkl\n",
      "Model loaded successfully.\n",
      "Embeddings loaded successfully.\n",
      "Hidden states loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "model, embeddings, hidden_states = import_embedding_data_from_pkl(\"Test_export_embeddings.pkl\", model=True, embeddings=True, hidden_states=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3014344f",
   "metadata": {},
   "source": [
    "## Checkpoint\n",
    "This cell will verify that everything has gone accodring to plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8988e2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üìã EMBEDDINGS CHECKPOINT\n",
      "============================================================\n",
      "‚úÖ Data loaded: 1000 movies\n",
      "‚úÖ Sample titles: ['The Shawshank Redemption', 'The Godfather', 'The Dark Knight']\n",
      "‚úÖ Required columns present: ['Poster_Link', 'title', 'Released_Year', 'Certificate', 'Runtime', 'IMDB_Rating', 'overview', 'Meta_score', 'Director', 'Star1', 'Star2', 'Star3', 'Star4', 'No_of_Votes', 'Gross', 'genre']\n",
      "‚úÖ Model loaded: sentence-transformers/all-MiniLM-L12-v2\n",
      "‚úÖ Embeddings shape: torch.Size([1000, 384])\n",
      "‚úÖ Hidden states: 13 layers\n",
      "‚úÖ Encoded input keys: ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "‚úÖ Export file created: Test_export_embeddings.pkl (1391.4 MB)\n",
      "‚úÖ Sample embedding values: [-0.06406020373106003, 0.055750492960214615, -0.051509786397218704]\n",
      "‚úÖ Embedding dimensions: 384\n",
      "============================================================\n",
      "üéØ CHECKPOINT PASSED - Ready for Steering Vector creation!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# üéØ CHECKPOINT 1: Embeddings Pipeline Validation\n",
    "print(\"=\"*60)\n",
    "print(\"üìã EMBEDDINGS CHECKPOINT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    # Verify data loading\n",
    "    print(f\"‚úÖ Data loaded: {len(all_texts_data)} movies\")\n",
    "    print(f\"‚úÖ Sample titles: {all_texts_data['title'].head(3).tolist()}\")\n",
    "    print(f\"‚úÖ Required columns present: {list(all_texts_data.columns)}\")\n",
    "    \n",
    "    # Verify model and embeddings\n",
    "    print(f\"‚úÖ Model loaded: {model_name}\")\n",
    "    print(f\"‚úÖ Embeddings shape: {embeddings.shape}\")\n",
    "    print(f\"‚úÖ Hidden states: {len(hidden_states)} layers\")\n",
    "    print(f\"‚úÖ Encoded input keys: {list(encoded_input.keys())}\")\n",
    "    \n",
    "    # Memory usage info\n",
    "    import os\n",
    "    if os.path.exists(\"Test_export_embeddings.pkl\"):\n",
    "        file_size = os.path.getsize(\"Test_export_embeddings.pkl\") / (1024*1024)\n",
    "        print(f\"‚úÖ Export file created: Test_export_embeddings.pkl ({file_size:.1f} MB)\")\n",
    "    \n",
    "    # Sample data validation\n",
    "    print(f\"‚úÖ Sample embedding values: {embeddings[0][:3].tolist()}\")\n",
    "    print(f\"‚úÖ Embedding dimensions: {embeddings.shape[1]}\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"üéØ CHECKPOINT PASSED - Ready for Steering Vector creation!\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"‚ùå CHECKPOINT FAILED\")\n",
    "    print(f\"üí• Error: {str(e)}\")\n",
    "    print(\"üîß Please check previous cells and re-run if necessary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8eeb8f2",
   "metadata": {},
   "source": [
    "***\n",
    "# <a id=\"steering-vector\"></a>Steering Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab80f41f",
   "metadata": {},
   "source": [
    "The following functions are imported from the file `\"Steering_vector.py\"`. They include all you need to create a steering vector for a selected feature. The text representing the feature is stored in a file called `\"feature.txt\"` in the folder \"feature\". In the same folder, you can add a file called `\"opposite.txt\"`, where text representing the opposite of the feature is stored.\n",
    "\n",
    "We again export the steering vectors to a pickle file so we do not need to create them multiple times. The file `\"steering_vector.pkl\"` can hold multiple features with the steering vector in multiple layers in a `dictionary`. To use the steering vector later, you can use the import function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac5c2d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from Steering_vector import import_feature_texts, get_steering_vector, export_steering_vector_to_pkl, import_steering_vector_from_pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c21ebe",
   "metadata": {},
   "source": [
    "## <a id=\"import-feature-texts\"></a>Import Feature Texts and <a id=\"get-steering-vector\"></a>Get Steering Vector\n",
    "\n",
    "Below we demonstrate importing feature texts and creating steering vectors.\n",
    "\n",
    "`import_feature_texts` reads the files `\"feature.txt\"` and `\"opposite.txt\"` stored in the folder named after the featre, e.g. War / Love. If the file is not present, it returns `None`. \n",
    "\n",
    "`get_steering_vector` creates the steering vector based on the feature text by embedding each line in the `.txt` files, before finding the mean embedding of these. \n",
    "- `layer_to_steer` decides what layer of the model outputs hidden states will be used for mean pooling. \n",
    "- You can also choose to normalize by setting `normalize=True`. We reccomend doing this as the steering vector should represent the direction of the feature, while the length/strength can be adjusted using a steering coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "670846ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opposite file not found: ../Functions/Features/Love/opposite.txt\n",
      "Model and tokenizer set for sentence-transformers/all-MiniLM-L12-v2\n",
      "Got embeddings for 25 texts using model: sentence-transformers/all-MiniLM-L12-v2\n",
      "Model and tokenizer set for sentence-transformers/all-MiniLM-L12-v2\n",
      "Got embeddings for 25 texts using model: sentence-transformers/all-MiniLM-L12-v2\n"
     ]
    }
   ],
   "source": [
    "# Import feature texts\n",
    "feature = \"Love\" # Choose a feature from the features directory.\n",
    "layer_to_steer = 11 # Choose layer to create a steering vector and export for.\n",
    "\n",
    "# Import feature texts and opposite feature texts\n",
    "feature_texts, opposite_feature_texts = import_feature_texts(f\"../Functions/Features/{feature}\")\n",
    "\n",
    "# Compute the steering vector\n",
    "model_name = \"sentence-transformers/all-MiniLM-L12-v2\"\n",
    "steering_vector = get_steering_vector(model_name, feature_texts, layer_to_steer=layer_to_steer, opposite_texts=opposite_feature_texts, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c112d08c",
   "metadata": {},
   "source": [
    "## <a id=\"export-steering-vector\"></a>Export Steering Vector\n",
    "\n",
    "We can now export the steering vector for later use using the function `export_steering_vector_to_pkl`. \n",
    "- `steering_vector` is the mean embedding we got from `get_steering_vector`\n",
    "- `file_path` is the path of the exported file\n",
    "- `feature_name` is what feature was used to create the steering vector to keep the file organised in a dictionary\n",
    "- `layer_to_steer` is what layer was steered when creating the steering vector, this also stored in the dictionary\n",
    "\n",
    "If you want to export the steering vector for all layers, simply loop through the functions `get_steering_vector` and `export_steering_vector_to_pkl` for each layer. We reccommend doing this to begin with, so you can analyze all layers without needing\n",
    "to create a new steering vector each time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd8c3f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steering vector for 'Love' (layer 11) exported to steering_vector.pkl\n"
     ]
    }
   ],
   "source": [
    "# Export the steering vector to a pkl file\n",
    "export_steering_vector_to_pkl(steering_vector, \"steering_vector.pkl\", feature_name=feature, layer_to_steer=layer_to_steer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88bad46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor feature in [\"War\", \"Love\", \"Norway\", \"Baseline\"]:\\n    feature_texts, opposite_feature_texts = import_feature_texts(f\"../Functions/Features/{feature}\")\\n    for i in range(12):\\n        steering_vector = get_steering_vector(model_name, feature_texts, layer_to_steer=i, opposite_texts=opposite_feature_texts, normalize=True)\\n        export_steering_vector_to_pkl(steering_vector, \"steering_vector.pkl\", feature_name=feature, layer_to_steer=i)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loop through all layers to create and export steering vectors for each layer. You will perhaps get a too many requests error, consider \n",
    "# Running two and two features at a time.\n",
    "'''\n",
    "for feature in [\"War\", \"Love\", \"Norway\", \"Baseline\"]:\n",
    "    feature_texts, opposite_feature_texts = import_feature_texts(f\"../Functions/Features/{feature}\")\n",
    "    for i in range(12):\n",
    "        steering_vector = get_steering_vector(model_name, feature_texts, layer_to_steer=i, opposite_texts=opposite_feature_texts, normalize=True)\n",
    "        export_steering_vector_to_pkl(steering_vector, \"steering_vector.pkl\", feature_name=feature, layer_to_steer=i)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63eba0f",
   "metadata": {},
   "source": [
    "## <a id=\"import-steering-vector\"></a>Import Steering Vector\n",
    "\n",
    "`import_steering_vector_from_pkl` allows you to import a selected steering vector\n",
    "\n",
    "- `file_path` is the path to the steering vector file\n",
    "- `feature_name` is the name of the wanted feature for the steering vector\n",
    "- `layer_to_steer` is what layer to retrieve the steering vector for (what layer to steer)\n",
    "\n",
    "Note: If `layer_to_steer=None`, the function will return the steering vectors for all layers for that feature as a dictionary with the structure: `{layer: vector_tensor, layer2: vector_tensor2, ...}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52036b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steering vectors imported from steering_vector.pkl\n",
      "Available steering vectors: 'War' (layers: [10, 11]), 'Love' (layers: [11])\n",
      "Returning steering vector for 'War' layer 11\n"
     ]
    }
   ],
   "source": [
    "# This is how to import the steering vector from the pkl file\n",
    "imported_steering_vector = import_steering_vector_from_pkl(\"steering_vector.pkl\", feature_name=\"War\", layer_to_steer=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d5d885",
   "metadata": {},
   "source": [
    "## Checkpoint\n",
    "This cell will verify that everything has gone accodring to plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "083ba727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üìã STEERING VECTOR CHECKPOINT\n",
      "============================================================\n",
      "‚úÖ Feature selected: 'Love'\n",
      "‚úÖ Feature texts loaded: 25 lines\n",
      "‚ÑπÔ∏è No opposite texts found (optional)\n",
      "‚úÖ Steering vector created for layer 11\n",
      "‚úÖ Steering vector shape: torch.Size([384])\n",
      "‚úÖ Vector norm: 1.0000\n",
      "‚úÖ Is normalized: True\n",
      "‚úÖ Steering vector exported: steering_vector.pkl (5.5 KB)\n",
      "Steering vectors imported from steering_vector.pkl\n",
      "Available steering vectors: 'War' (layers: [10, 11]), 'Love' (layers: [11])\n",
      "Returning steering vector for 'Love' layer 11\n",
      "‚úÖ Import verification: torch.Size([384])\n",
      "‚úÖ Sample vector values: [0.00398731604218483, 0.07698136568069458, 0.027998507022857666]\n",
      "============================================================\n",
      "üéØ CHECKPOINT PASSED - Ready for Steering operations!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# üéØ CHECKPOINT 2: Steering Vector Pipeline Validation\n",
    "print(\"=\"*60)\n",
    "print(\"üìã STEERING VECTOR CHECKPOINT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    # Verify feature texts loading\n",
    "    print(f\"‚úÖ Feature selected: '{feature}'\")\n",
    "    print(f\"‚úÖ Feature texts loaded: {len(feature_texts) if feature_texts else 0} lines\")\n",
    "    if opposite_feature_texts:\n",
    "        print(f\"‚úÖ Opposite texts loaded: {len(opposite_feature_texts)} lines\")\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è No opposite texts found (optional)\")\n",
    "    \n",
    "    # Verify steering vector creation\n",
    "    import torch\n",
    "    print(f\"‚úÖ Steering vector created for layer {layer_to_steer}\")\n",
    "    print(f\"‚úÖ Steering vector shape: {steering_vector.shape}\")\n",
    "    print(f\"‚úÖ Vector norm: {torch.norm(steering_vector):.4f}\")\n",
    "    print(f\"‚úÖ Is normalized: {torch.allclose(torch.norm(steering_vector), torch.tensor(1.0))}\")\n",
    "    \n",
    "    # Verify export file\n",
    "    import os\n",
    "    if os.path.exists(\"steering_vector.pkl\"):\n",
    "        file_size = os.path.getsize(\"steering_vector.pkl\") / 1024  # KB\n",
    "        print(f\"‚úÖ Steering vector exported: steering_vector.pkl ({file_size:.1f} KB)\")\n",
    "    \n",
    "    # Verify import functionality\n",
    "    test_import = import_steering_vector_from_pkl(\"steering_vector.pkl\", feature_name=feature, layer_to_steer=layer_to_steer)\n",
    "    print(f\"‚úÖ Import verification: {test_import.shape}\")\n",
    "    \n",
    "    # Sample vector values\n",
    "    print(f\"‚úÖ Sample vector values: {steering_vector[:3].tolist()}\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"üéØ CHECKPOINT PASSED - Ready for Steering operations!\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"‚ùå CHECKPOINT FAILED\")\n",
    "    print(f\"üí• Error: {str(e)}\")\n",
    "    print(\"üîß Please check previous cells and re-run if necessary\")\n",
    "    print(\"üí° Tip: Ensure feature texts exist in ../Functions/Features/{feature}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0474a3c",
   "metadata": {},
   "source": [
    "***\n",
    "# <a id=\"steering\"></a>Steering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a8b266",
   "metadata": {},
   "source": [
    "The following functions are imported from the file `\"Steering.py\"` and include what you need to create the steered embeddings and outputs using either the steering vector, or chosing to steer on a specific node in a specific layer. We will reuse the function `import_embedding_data_from_pkl` that we saw under Embeddings, and the `import_steering_vector_from_pkl` we saw under Steering Vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c719615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from Steering import get_steered_embeddings_vector, get_steered_embeddings_neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd197fd4",
   "metadata": {},
   "source": [
    "## <a id=\"get-steered-embeddings-vector\"></a>Get Steered Embeddings (Vector)\n",
    "\n",
    "Below we demonstrate steering using a semantic vector:\n",
    "\n",
    "`get_steered_embeddings_vector` creates steered embeddings using the steering vector. You must first import the `model` and `encoded_input` you used for the original embeddings.\n",
    "\n",
    "- `layer_to_steer` is what layer you are wanting to steer. This should be the same as the layer of the imported steering_vector. If no layer is specefied for the steering vector, the function will use this parameter to choose what layer to use as the steering vector.\n",
    "- `steering_coefficient` is the coefficient which you multiply the steering vector with in the steering hook\n",
    "- `steering_vector` is the chosen steering vector. This can be a dictionary of all the layers with the respective vector, or a single vector\n",
    "- `normalize` will normalize the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c719615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Steering import get_steered_embeddings_vector, get_steered_embeddings_neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbf46497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing 1.36 GB data from file Test_export_embeddings.pkl...\n",
      "Data imported from Test_export_embeddings.pkl\n",
      "Model loaded successfully.\n",
      "Encoded input loaded successfully.\n",
      "Steering vectors imported from steering_vector.pkl\n",
      "Available steering vectors: 'War' (layers: [10, 11]), 'Love' (layers: [11])\n",
      "Returning all layers for 'War': [10, 11]\n",
      "Data imported from Test_export_embeddings.pkl\n",
      "Model loaded successfully.\n",
      "Encoded input loaded successfully.\n",
      "Steering vectors imported from steering_vector.pkl\n",
      "Available steering vectors: 'War' (layers: [10, 11]), 'Love' (layers: [11])\n",
      "Returning all layers for 'War': [10, 11]\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "model, encoded_input = import_embedding_data_from_pkl('Test_export_embeddings.pkl', model=True, encoded_input=True)\n",
    "steering_vector = import_steering_vector_from_pkl('steering_vector.pkl', 'War') # If no layer is specified, all vectors are returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "924626e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created steered model output with shape: torch.Size([1000, 66, 384])\n",
      "Created steered embeddings with shape: torch.Size([1000, 384])\n"
     ]
    }
   ],
   "source": [
    "# Here we compute the steered embeddings using the steering vector from a specific layer.\n",
    "\n",
    "steered_embeddings_vector = get_steered_embeddings_vector(\n",
    "    model, \n",
    "    encoded_input, \n",
    "    layer_to_steer=11, \n",
    "    steering_coefficient=0.5, \n",
    "    steering_vector=steering_vector, # If all vectors are passed, only the selected layer is used\n",
    "    normalize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5a86e3",
   "metadata": {},
   "source": [
    "## <a id=\"get-steered-embeddings-neuron\"></a>Get Steered Embeddings (Neuron)\n",
    "\n",
    "`get_steered_embeddings_neuron` can be used to create steered embeddings when steering on a single neuron in a specified layer.\n",
    "- `layer_to_steer` is in what layer you want to steer your neuron\n",
    "- `node_to_steer` is the neuron index of the neuron you want to steer. This can be either `int`or `tuple`, where a tuple will steer on the neurons listed.\n",
    "- `steering_coefficient` is the number you will add to the output in the steering hook. This can be either `int`or `tuple`, where a tuple will steer the corresponding indexed neurons in `node_to_steer` by that coefficient.\n",
    "- `normalize` will normalize the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9166a2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created steered model output with shape: torch.Size([1000, 66, 384])\n",
      "Created steered embeddings with shape: torch.Size([1000, 384])\n"
     ]
    }
   ],
   "source": [
    "# Here we compute the steered embeddings using a specific neuron in a specific layer.\n",
    "\n",
    "steered_embeddings_neuron = get_steered_embeddings_neuron(\n",
    "    model, \n",
    "    encoded_input, \n",
    "    layer_to_steer=11,\n",
    "    node_to_steer=0, \n",
    "    steering_coefficient=0.5,\n",
    "    normalize=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9a52a5",
   "metadata": {},
   "source": [
    "If you want to steer on multiple neurons, you can pass a `tuple` of neuron indices and a tuple of steering coefficients. \n",
    "This will steer neuron 0 with a coefficient of 0.5, neuron 42 with a coefficient of 1, and neuron 100 with a coefficient of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5ccc4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created steered model output with shape: torch.Size([1000, 66, 384])\n",
      "Created steered embeddings with shape: torch.Size([1000, 384])\n"
     ]
    }
   ],
   "source": [
    "steered_embeddings_neurons = get_steered_embeddings_neuron(\n",
    "    model, \n",
    "    encoded_input, \n",
    "    layer_to_steer=11, \n",
    "    node_to_steer=(0, 42, 100),\n",
    "    steering_coefficient=(0.5, 1, 2), \n",
    "    normalize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9004430",
   "metadata": {},
   "source": [
    "## Checkpoint\n",
    "This cell will verify that everything has gone accodring to plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738c09fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üìã STEERING OPERATIONS CHECKPOINT\n",
      "============================================================\n",
      "‚úÖ Model and encoded_input loaded for steering\n",
      "‚úÖ Steering vector imported for 'War' feature\n",
      "‚úÖ Vector steering completed\n",
      "‚úÖ Steered embeddings (vector) shape: torch.Size([1000, 384])\n",
      "‚úÖ Steering applied to layer 11 with coefficient 0.5\n",
      "‚úÖ Single neuron steering completed\n",
      "‚úÖ Steered embeddings (neuron) shape: torch.Size([1000, 384])\n",
      "‚úÖ Neuron 0 steered with coefficient 0.5\n",
      "‚úÖ Multi-neuron steering completed\n",
      "‚úÖ Steered embeddings (neurons) shape: torch.Size([1000, 384])\n",
      "‚úÖ Neurons (0, 42, 100) steered with coefficients (0.5, 1, 2)\n",
      "‚úÖ Original sample: [-0.06406020373106003, 0.055750492960214615, -0.051509786397218704]\n",
      "‚úÖ Vector steered sample: [-0.06847507506608963, 0.05591105297207832, -0.06437089294195175]\n",
      "‚úÖ Vector steering magnitude: 0.0136\n",
      "‚úÖ Neuron steering magnitude: 0.1220\n",
      "============================================================\n",
      "üéØ ALL CHECKPOINTS PASSED - Analysis pipeline complete!\n",
      "üöÄ Ready for downstream analysis (PCA, t-SNE, ranking, etc.)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# üéØ CHECKPOINT 3: Steering Operations Validation\n",
    "print(\"=\"*60)\n",
    "print(\"üìã STEERING OPERATIONS CHECKPOINT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    # Verify data imports for steering\n",
    "    print(f\"‚úÖ Model and encoded_input loaded for steering\")\n",
    "    print(f\"‚úÖ Steering vector imported for 'War' feature\")\n",
    "    \n",
    "    # Verify vector steering\n",
    "    print(f\"‚úÖ Vector steering completed\")\n",
    "    print(f\"‚úÖ Steered embeddings (vector) shape: {steered_embeddings_vector.shape}\")\n",
    "    print(f\"‚úÖ Steering applied to layer 11 with coefficient 0.5\")\n",
    "    \n",
    "    # Verify neuron steering (single)\n",
    "    print(f\"‚úÖ Single neuron steering completed\")\n",
    "    print(f\"‚úÖ Steered embeddings (neuron) shape: {steered_embeddings_neuron.shape}\")\n",
    "    print(f\"‚úÖ Neuron 0 steered with coefficient 0.5\")\n",
    "    \n",
    "    # Verify multi-neuron steering\n",
    "    print(f\"‚úÖ Multi-neuron steering completed\")\n",
    "    print(f\"‚úÖ Steered embeddings (neurons) shape: {steered_embeddings_neurons.shape}\")\n",
    "    print(f\"‚úÖ Neurons (0, 42, 100) steered with coefficients (0.5, 1, 2)\")\n",
    "    \n",
    "    # Compare original vs steered embeddings\n",
    "    original_sample = embeddings[0][:3]\n",
    "    steered_vector_sample = steered_embeddings_vector[0][:3]\n",
    "    steered_neuron_sample = steered_embeddings_neuron[0][:3]\n",
    "    \n",
    "    import torch\n",
    "    vector_diff = torch.norm(steered_vector_sample - original_sample)\n",
    "    neuron_diff = torch.norm(steered_neuron_sample - original_sample)\n",
    "    \n",
    "    print(f\"‚úÖ Original sample: {original_sample.tolist()}\")\n",
    "    print(f\"‚úÖ Vector steered sample: {steered_vector_sample.tolist()}\")\n",
    "    print(f\"‚úÖ Vector steering magnitude: {vector_diff:.4f}\")\n",
    "    print(f\"‚úÖ Neuron steering magnitude: {neuron_diff:.4f}\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"üéØ ALL CHECKPOINTS PASSED - Analysis pipeline complete!\")\n",
    "    print(\"üöÄ Ready to move on to Notebook 2 (PCA, t-SNE, ranking, etc.)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"‚ùå CHECKPOINT FAILED\")\n",
    "    print(f\"üí• Error: {str(e)}\")\n",
    "    print(\"üîß Please check previous cells and re-run if necessary\")\n",
    "    print(\"üí° Tip: Ensure all previous checkpoints passed successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
